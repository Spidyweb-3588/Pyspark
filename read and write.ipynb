{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"sample\").master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = spark.read.format(\"csv\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").load(\"C:/Users/b2en/Desktop/read write test/201508_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. 데이터를 읽어서 parquet 형식 파일로 저장하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.write.format(\"parquet\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-parquet-file\") #parquet 파일은 write 시에 header option을 안줘도 컬럼명을 읽어온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.write.format(\"csv\")\\\n",
    "       .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file\") #csv 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Start Station 별로 partition하여 저장하시오 (partition이 된다는 것은 안에 디렉토리로 구분이 된다는 것.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.write.format(\"parquet\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .partitionBy(\"Start_Station\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-parquet_file_start_station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. (non-partition으로) 데이터 셋을 1개의 parquet 파일로 저장하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.coalesce(1).write.format(\"parquet\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_withone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.coalesce(1).write.format(\"csv\")\\\n",
    "       .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_withone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. (non-partition으로) 데이터 셋을 5개의 파일로 나누어 저장하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.repartition(5).write.format(\"parquet\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_withfive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.repartition(5).write.format(\"csv\")\\\n",
    "       .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_withfive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. csv로 적재된 원본 데이터 셋을 partition 당 사이즈가 10MB를 넘지 않도록 나누어 data frame에 적재하시오.\n",
    "  - partition은 spark의 partition으르 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_csvfile = spark.read.format(\"csv\")\\\n",
    "                       .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "                       .load(\"C:/Users/b2en/Desktop/read write test/201508_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_csvfile.write.format(\"csv\")\\\n",
    "               .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "               .mode(\"overwrite\")\\\n",
    "               .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_limited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. (non-partition으로) 데이터 셋을 파일당 10만개 Row를 보관하도록 저장하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.repartition(1).write.format(\"parquet\")\\\n",
    "       .option(\"maxRecordsPerFile\", 100000)\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_10M\")#parquet는 컬럼명제외 10만개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile.repartition(1).write.format(\"csv\")\\\n",
    "       .option(\"maxRecordsPerFile\", 100000)\\\n",
    "       .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "       .mode(\"overwrite\")\\\n",
    "       .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_10M\")#csv는 컬럼명 포함 10만1개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"csv\")\\\n",
    "     .load(\"C:/Users/b2en/Desktop/read write test/my-csv-file_10M/part-00000-5c8d4f66-1644-4f3c-8020-cf9880b28b98-c002.csv\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"parquet\")\\\n",
    "     .load(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_10M/part-00000-4f8c3057-78af-4b0e-9e94-bd467f6362a0-c002.snappy.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"parquet\")\\\n",
    "     .load(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_10M/part-00000-f9ed8510-f4bd-40f7-bd3b-7dccc7178f73-c003.snappy.parquet\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. \"Start Date\" 컬럼을 기준으로 partition 형태로 저장하시오\n",
    "      - 년도-월-일 별로 partition하여 저장하시오. (3개 partition key)\n",
    "      - 단, 저장 시에 원본의 컬럼은 모두 유지되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "splitcol = split(csvfile['Start_Date'], '/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_csvfile = \\\n",
    "csvfile.withColumn(\"year_time\",splitcol.getItem(2))\\\n",
    "       .withColumn(\"month\",splitcol.getItem(0))\\\n",
    "       .withColumn(\"day\",splitcol.getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_space = split(split_csvfile[\"year_time\"],' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csvfile =\\\n",
    "split_csvfile.withColumn(\"year\",split_space.getItem(0))\\\n",
    "             .drop(\"year_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csvfile.write.format(\"parquet\")\\\n",
    "                 .mode(\"overwrite\")\\\n",
    "                 .partitionBy(\"year\",\"month\",\"day\")\\\n",
    "                 .save(\"C:/Users/b2en/Desktop/read write test/my-parquet-file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csvfile.write.format(\"csv\")\\\n",
    "                 .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "                 .mode(\"overwrite\")\\\n",
    "                 .partitionBy(\"year\",\"month\",\"day\")\\\n",
    "                 .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unix timestamp로 데이터프레임짜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_date =\\\n",
    "csvfile.withColumn(\"Start_Date2\",from_unixtime(unix_timestamp(csvfile.Start_Date,\"MM/dd/yyyy HH:mm\")))\\\n",
    "       .withColumn(\"year\",substring(\"Start_Date2\",1,4))\\\n",
    "       .withColumn(\"month\",substring(\"Start_Date2\",6,2))\\\n",
    "       .withColumn(\"day\",substring(\"Start_Date2\",9,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_date.write.format(\"csv\")\\\n",
    "                 .option(\"inferSchema\",\"true\").option(\"header\",\"true\")\\\n",
    "                 .mode(\"overwrite\")\\\n",
    "                 .partitionBy(\"year\",\"month\",\"day\")\\\n",
    "                 .save(\"C:/Users/b2en/Desktop/read write test/my-csv-file_date2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7-a. partition으로 저장한 파일을 read 하시오.\n",
    "      - 년도, 월, 일 조건 입력 시 partition prunning이 발생하는 지 확인하시오.\n",
    "      - 저장한 파일을 df로 적재하여, 특정 조건만 추출하는 spark program 테스트를 진행합니다.\n",
    "      - partition prunning의 발생 여부 확인 방법은 각자의 지식과 아이디어로 찾아주시고, 합리적으로 확인할 수만 있으면 가능합니다.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_pc_csv = spark.read.format(\"csv\")\\\n",
    "                    .option(\"inferSchema\",\"True\").option(\"header\",\"true\").option(\"basepath\",\"file:///C:/Users/b2en/Desktop/read write test/my-csv-file_date/\")\\\n",
    "                    .load(\"C:/Users/b2en/Desktop/read write test/my-csv-file_date/year=2014/month=9/day=10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Trip_ID</th><th>Duration</th><th>Start_Date</th><th>Start_Station</th><th>Start_Terminal</th><th>End_Date</th><th>End_Station</th><th>End_Terminal</th><th>Bike_#</th><th>Subscriber_Type</th><th>Zip_Code</th></tr>\n",
       "<tr><td>447446</td><td>189</td><td>9/10/2014 23:16</td><td>San Jose Diridon ...</td><td>2</td><td>9/10/2014 23:19</td><td>Santa Clara at Al...</td><td>4</td><td>145</td><td>Subscriber</td><td>95110</td></tr>\n",
       "<tr><td>447445</td><td>339</td><td>9/10/2014 23:09</td><td>San Francisco Cal...</td><td>69</td><td>9/10/2014 23:15</td><td>5th at Howard</td><td>57</td><td>524</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447443</td><td>264</td><td>9/10/2014 22:49</td><td>Howard at 2nd</td><td>63</td><td>9/10/2014 22:53</td><td>2nd at South Park</td><td>64</td><td>321</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447442</td><td>735</td><td>9/10/2014 22:48</td><td>Powell Street BART</td><td>39</td><td>9/10/2014 23:00</td><td>San Francisco Cal...</td><td>69</td><td>387</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447440</td><td>751</td><td>9/10/2014 22:30</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:42</td><td>Embarcadero at Sa...</td><td>60</td><td>481</td><td>Customer</td><td>37402</td></tr>\n",
       "<tr><td>447439</td><td>770</td><td>9/10/2014 22:29</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:42</td><td>Embarcadero at Sa...</td><td>60</td><td>512</td><td>Customer</td><td>37402</td></tr>\n",
       "<tr><td>447438</td><td>61</td><td>9/10/2014 22:24</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:25</td><td>2nd at Townsend</td><td>61</td><td>406</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447437</td><td>2329</td><td>9/10/2014 22:23</td><td>San Jose Civic Ce...</td><td>3</td><td>9/10/2014 23:02</td><td>San Jose Civic Ce...</td><td>3</td><td>156</td><td>Customer</td><td>63051</td></tr>\n",
       "<tr><td>447436</td><td>709</td><td>9/10/2014 22:17</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:29</td><td>Broadway St at Ba...</td><td>82</td><td>334</td><td>Subscriber</td><td>94112</td></tr>\n",
       "<tr><td>447435</td><td>1147</td><td>9/10/2014 22:14</td><td>University and Em...</td><td>35</td><td>9/10/2014 22:33</td><td>Park at Olive</td><td>38</td><td>21</td><td>Customer</td><td>94306</td></tr>\n",
       "<tr><td>447434</td><td>304</td><td>9/10/2014 22:11</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:17</td><td>Spear at Folsom</td><td>49</td><td>522</td><td>Subscriber</td><td>94123</td></tr>\n",
       "<tr><td>447433</td><td>140</td><td>9/10/2014 22:07</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:10</td><td>San Francisco Cal...</td><td>69</td><td>607</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447432</td><td>563</td><td>9/10/2014 22:05</td><td>San Francisco Cal...</td><td>70</td><td>9/10/2014 22:14</td><td>Powell Street BART</td><td>39</td><td>547</td><td>Subscriber</td><td>94609</td></tr>\n",
       "<tr><td>447431</td><td>679</td><td>9/10/2014 22:02</td><td>San Francisco Cal...</td><td>70</td><td>9/10/2014 22:13</td><td>Grant Avenue at C...</td><td>73</td><td>389</td><td>Subscriber</td><td>94133</td></tr>\n",
       "<tr><td>447430</td><td>458</td><td>9/10/2014 22:00</td><td>San Francisco Cal...</td><td>70</td><td>9/10/2014 22:07</td><td>2nd at Folsom</td><td>62</td><td>292</td><td>Subscriber</td><td>94107</td></tr>\n",
       "<tr><td>447429</td><td>281</td><td>9/10/2014 21:49</td><td>San Pedro Square</td><td>6</td><td>9/10/2014 21:54</td><td>San Jose City Hall</td><td>10</td><td>257</td><td>Customer</td><td>94538</td></tr>\n",
       "<tr><td>447427</td><td>296</td><td>9/10/2014 21:48</td><td>Embarcadero at Sa...</td><td>60</td><td>9/10/2014 21:53</td><td>Steuart at Market</td><td>74</td><td>521</td><td>Subscriber</td><td>94517</td></tr>\n",
       "<tr><td>447426</td><td>369</td><td>9/10/2014 21:47</td><td>Spear at Folsom</td><td>49</td><td>9/10/2014 21:53</td><td>2nd at Townsend</td><td>61</td><td>406</td><td>Subscriber</td><td>94030</td></tr>\n",
       "<tr><td>447425</td><td>414</td><td>9/10/2014 21:47</td><td>Spear at Folsom</td><td>49</td><td>9/10/2014 21:54</td><td>2nd at Townsend</td><td>61</td><td>529</td><td>Subscriber</td><td>94109</td></tr>\n",
       "<tr><td>447424</td><td>1397</td><td>9/10/2014 21:42</td><td>2nd at Townsend</td><td>61</td><td>9/10/2014 22:06</td><td>Civic Center BART...</td><td>72</td><td>554</td><td>Subscriber</td><td>94107</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
       "|Trip_ID|Duration|     Start_Date|       Start_Station|Start_Terminal|       End_Date|         End_Station|End_Terminal|Bike_#|Subscriber_Type|Zip_Code|\n",
       "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
       "| 447446|     189|9/10/2014 23:16|San Jose Diridon ...|             2|9/10/2014 23:19|Santa Clara at Al...|           4|   145|     Subscriber|   95110|\n",
       "| 447445|     339|9/10/2014 23:09|San Francisco Cal...|            69|9/10/2014 23:15|       5th at Howard|          57|   524|     Subscriber|   94107|\n",
       "| 447443|     264|9/10/2014 22:49|       Howard at 2nd|            63|9/10/2014 22:53|   2nd at South Park|          64|   321|     Subscriber|   94107|\n",
       "| 447442|     735|9/10/2014 22:48|  Powell Street BART|            39|9/10/2014 23:00|San Francisco Cal...|          69|   387|     Subscriber|   94107|\n",
       "| 447440|     751|9/10/2014 22:30|     2nd at Townsend|            61|9/10/2014 22:42|Embarcadero at Sa...|          60|   481|       Customer|   37402|\n",
       "| 447439|     770|9/10/2014 22:29|     2nd at Townsend|            61|9/10/2014 22:42|Embarcadero at Sa...|          60|   512|       Customer|   37402|\n",
       "| 447438|      61|9/10/2014 22:24|     2nd at Townsend|            61|9/10/2014 22:25|     2nd at Townsend|          61|   406|     Subscriber|   94107|\n",
       "| 447437|    2329|9/10/2014 22:23|San Jose Civic Ce...|             3|9/10/2014 23:02|San Jose Civic Ce...|           3|   156|       Customer|   63051|\n",
       "| 447436|     709|9/10/2014 22:17|     2nd at Townsend|            61|9/10/2014 22:29|Broadway St at Ba...|          82|   334|     Subscriber|   94112|\n",
       "| 447435|    1147|9/10/2014 22:14|University and Em...|            35|9/10/2014 22:33|       Park at Olive|          38|    21|       Customer|   94306|\n",
       "| 447434|     304|9/10/2014 22:11|     2nd at Townsend|            61|9/10/2014 22:17|     Spear at Folsom|          49|   522|     Subscriber|   94123|\n",
       "| 447433|     140|9/10/2014 22:07|     2nd at Townsend|            61|9/10/2014 22:10|San Francisco Cal...|          69|   607|     Subscriber|   94107|\n",
       "| 447432|     563|9/10/2014 22:05|San Francisco Cal...|            70|9/10/2014 22:14|  Powell Street BART|          39|   547|     Subscriber|   94609|\n",
       "| 447431|     679|9/10/2014 22:02|San Francisco Cal...|            70|9/10/2014 22:13|Grant Avenue at C...|          73|   389|     Subscriber|   94133|\n",
       "| 447430|     458|9/10/2014 22:00|San Francisco Cal...|            70|9/10/2014 22:07|       2nd at Folsom|          62|   292|     Subscriber|   94107|\n",
       "| 447429|     281|9/10/2014 21:49|    San Pedro Square|             6|9/10/2014 21:54|  San Jose City Hall|          10|   257|       Customer|   94538|\n",
       "| 447427|     296|9/10/2014 21:48|Embarcadero at Sa...|            60|9/10/2014 21:53|   Steuart at Market|          74|   521|     Subscriber|   94517|\n",
       "| 447426|     369|9/10/2014 21:47|     Spear at Folsom|            49|9/10/2014 21:53|     2nd at Townsend|          61|   406|     Subscriber|   94030|\n",
       "| 447425|     414|9/10/2014 21:47|     Spear at Folsom|            49|9/10/2014 21:54|     2nd at Townsend|          61|   529|     Subscriber|   94109|\n",
       "| 447424|    1397|9/10/2014 21:42|     2nd at Townsend|            61|9/10/2014 22:06|Civic Center BART...|          72|   554|     Subscriber|   94107|\n",
       "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_pc_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation[Trip_ID#54,Duration#55,Start_Date#56,Start_Station#57,Start_Terminal#58,End_Date#59,End_Station#60,End_Terminal#61,Bike_##62,Subscriber_Type#63,Zip_Code#64] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Trip_ID: int, Duration: int, Start_Date: string, Start_Station: string, Start_Terminal: int, End_Date: string, End_Station: string, End_Terminal: int, Bike_#: int, Subscriber_Type: string, Zip_Code: string\n",
      "Relation[Trip_ID#54,Duration#55,Start_Date#56,Start_Station#57,Start_Terminal#58,End_Date#59,End_Station#60,End_Terminal#61,Bike_##62,Subscriber_Type#63,Zip_Code#64] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation[Trip_ID#54,Duration#55,Start_Date#56,Start_Station#57,Start_Terminal#58,End_Date#59,End_Station#60,End_Terminal#61,Bike_##62,Subscriber_Type#63,Zip_Code#64] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [Trip_ID#54,Duration#55,Start_Date#56,Start_Station#57,Start_Terminal#58,End_Date#59,End_Station#60,End_Terminal#61,Bike_##62,Subscriber_Type#63,Zip_Code#64] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/b2en/Desktop/read write test/my-csv-file_date/year=2014/month=9/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Trip_ID:int,Duration:int,Start_Date:string,Start_Station:string,Start_Terminal:int,End_Dat...\n"
     ]
    }
   ],
   "source": [
    "saved_pc_csv.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_pc_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_pc_csv_all = spark.read.format(\"csv\")\\\n",
    "                        .option(\"inferSchema\",\"True\").option(\"header\",\"true\").option(\"basepath\",\"C:/Users/b2en/Desktop/read write test/my-csv-file_date/\")\\\n",
    "                        .load(\"C:/Users/b2en/Desktop/read write test/my-csv-file_date/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_pc_csv_all.where((saved_pc_csv_all[\"year\"] == 2014) & (saved_pc_csv_all[\"month\"] == 9) & (saved_pc_csv_all[\"day\"] == 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_pc_csv_all.where((saved_pc_csv_all[\"year\"] == 2014) & (saved_pc_csv_all[\"month\"] == 9) & (saved_pc_csv_all[\"day\"] == 10)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Filter (((year#109 = 2014) && (month#110 = 9)) && (day#111 = 10))\n",
      "+- Relation[Trip_ID#98,Duration#99,Start_Date#100,Start_Station#101,Start_Terminal#102,End_Date#103,End_Station#104,End_Terminal#105,Bike_##106,Subscriber_Type#107,Zip_Code#108,year#109,month#110,day#111] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Trip_ID: int, Duration: int, Start_Date: string, Start_Station: string, Start_Terminal: int, End_Date: string, End_Station: string, End_Terminal: int, Bike_#: int, Subscriber_Type: string, Zip_Code: string, year: int, month: int, day: int\n",
      "Filter (((year#109 = 2014) && (month#110 = 9)) && (day#111 = 10))\n",
      "+- Relation[Trip_ID#98,Duration#99,Start_Date#100,Start_Station#101,Start_Terminal#102,End_Date#103,End_Station#104,End_Terminal#105,Bike_##106,Subscriber_Type#107,Zip_Code#108,year#109,month#110,day#111] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (((((isnotnull(year#109) && isnotnull(day#111)) && isnotnull(month#110)) && (year#109 = 2014)) && (month#110 = 9)) && (day#111 = 10))\n",
      "+- Relation[Trip_ID#98,Duration#99,Start_Date#100,Start_Station#101,Start_Terminal#102,End_Date#103,End_Station#104,End_Terminal#105,Bike_##106,Subscriber_Type#107,Zip_Code#108,year#109,month#110,day#111] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [Trip_ID#98,Duration#99,Start_Date#100,Start_Station#101,Start_Terminal#102,End_Date#103,End_Station#104,End_Terminal#105,Bike_##106,Subscriber_Type#107,Zip_Code#108,year#109,month#110,day#111] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/b2en/Desktop/read write test/my-csv-file_date], PartitionCount: 1, PartitionFilters: [isnotnull(year#109), isnotnull(day#111), isnotnull(month#110), (year#109 = 2014), (month#110 = 9..., PushedFilters: [], ReadSchema: struct<Trip_ID:int,Duration:int,Start_Date:string,Start_Station:string,Start_Terminal:int,End_Dat...\n"
     ]
    }
   ],
   "source": [
    "saved_pc_csv_all.where((saved_pc_csv_all[\"year\"] == 2014) & (saved_pc_csv_all[\"month\"] == 9) & (saved_pc_csv_all[\"day\"] == 10)).explain(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
